# Flash-Attention-with-Triton
This repository contains an optimized implementation of the FlashAttention algorithm written in OpenAI Triton.
